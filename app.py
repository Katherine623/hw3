import streamlit as stimport streamlit as st

import pandas as pdimport pandas as pd

import numpy as npfrom sklearn.model_selection import train_test_split

from sklearn.model_selection import train_test_splitfrom sklearn.feature_extraction.text import TfidfVectorizer

from sklearn.feature_extraction.text import TfidfVectorizerfrom sklearn.ensemble import RandomForestClassifier

from sklearn.ensemble import RandomForestClassifierfrom sklearn.metrics import accuracy_score

from sklearn.linear_model import LogisticRegression

from sklearn.naive_bayes import MultinomialNB# Set page configuration

from sklearn.svm import LinearSVCst.set_page_config(

from sklearn.metrics import (    page_title="Spam/Ham Classifier",

    accuracy_score, precision_score, recall_score, f1_score,    page_icon="ğŸ“§",

    confusion_matrix, roc_curve, auc    layout="wide"

))

import plotly.express as px

import plotly.graph_objects as go# Add title and description

from plotly.subplots import make_subplotsst.title("åƒåœ¾éƒµä»¶åˆ†é¡ç³»çµ± - Spam/Ham Classifier")

import timest.markdown("""

é€™æ˜¯ä¸€å€‹ä½¿ç”¨æ©Ÿå™¨å­¸ç¿’æŠ€è¡“çš„åƒåœ¾éƒµä»¶åˆ†é¡ç³»çµ±ã€‚ç³»çµ±èƒ½å¤ åˆ†æéƒµä»¶å…§å®¹ï¼Œä¸¦é æ¸¬å®ƒæ˜¯åƒåœ¾éƒµä»¶ï¼ˆspamï¼‰é‚„æ˜¯æ­£å¸¸éƒµä»¶ï¼ˆhamï¼‰ã€‚

# Set page configuration""")

st.set_page_config(

    page_title="åƒåœ¾éƒµä»¶åˆ†é¡ç³»çµ±",# Load and preprocess data

    page_icon="ğŸ“§",@st.cache_data

    layout="wide"def load_data():

)    try:

        df = pd.read_csv('sms_spam_clean.csv')

# Title        return df

st.title("ğŸ“§ åƒåœ¾éƒµä»¶åˆ†é¡ç³»çµ±")    except Exception as e:

st.markdown("ä½¿ç”¨å¤šç¨®æ©Ÿå™¨å­¸ç¿’æ¨¡å‹é€²è¡Œåƒåœ¾éƒµä»¶åˆ†é¡")        st.error(f"è®€å–è³‡æ–™éŒ¯èª¤: {str(e)}")

        return None

# Sidebar

with st.sidebar:# Load the data

    st.title("è¨­å®šé¸é …")df = load_data()

    

    model_choice = st.selectbox(if df is None:

        "é¸æ“‡åˆ†é¡å™¨",    st.stop()

        ["Random Forest", "Logistic Regression", "NaÃ¯ve Bayes", "SVM (Linear)", "æ‰€æœ‰æ¨¡å‹æ¯”è¼ƒ"]

    )# Create tabs

    tab1, tab2 = st.tabs(["é æ¸¬", "æ•¸æ“šåˆ†æ"])

    test_size = st.slider("æ¸¬è©¦é›†æ¯”ä¾‹", 0.1, 0.4, 0.2, 0.05)

    max_features = st.slider("æœ€å¤§ç‰¹å¾µæ•¸ (TF-IDF)", 500, 2000, 1000, 100)with tab1:

    st.header("éƒµä»¶åˆ†é¡é æ¸¬")

# Load data    

@st.cache_data    # Text input for prediction

def load_data():    user_input = st.text_area("è«‹è¼¸å…¥è¦åˆ†é¡çš„éƒµä»¶å…§å®¹ï¼š", height=100)

    try:    

        df = pd.read_csv('sms_spam_clean.csv')    # Model training and prediction

        return df    if user_input:

    except Exception as e:        # Prepare the model

        st.error(f"è®€å–è³‡æ–™éŒ¯èª¤: {str(e)}")        vectorizer = TfidfVectorizer(max_features=1000)

        return None        X = vectorizer.fit_transform(df['text_clean'])

        y = (df['col_0'] == 'spam').astype(int)

# Train model        

@st.cache_data        # Split the data

def train_model(model_name, X_train, y_train, X_test, y_test):        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    if model_name == "Random Forest":        

        model = RandomForestClassifier(n_estimators=100, random_state=42)        # Train the model

    elif model_name == "Logistic Regression":        model = RandomForestClassifier(n_estimators=100, random_state=42)

        model = LogisticRegression(max_iter=1000, random_state=42)        model.fit(X_train, y_train)

    elif model_name == "NaÃ¯ve Bayes":        

        model = MultinomialNB()        # Make prediction

    else:  # SVM        user_vector = vectorizer.transform([user_input])

        model = LinearSVC(random_state=42, max_iter=2000)        prediction = model.predict(user_vector)

            probability = model.predict_proba(user_vector)

    start_time = time.time()        

    model.fit(X_train, y_train)        # Show results

    train_time = time.time() - start_time        col1, col2 = st.columns(2)

            

    y_pred = model.predict(X_test)        with col1:

                st.subheader("é æ¸¬çµæœ")

    # Get probabilities if available            if prediction[0] == 1:

    if hasattr(model, 'predict_proba'):                st.error("âš ï¸ é€™å¯èƒ½æ˜¯åƒåœ¾éƒµä»¶ (Spam)")

        y_prob = model.predict_proba(X_test)[:, 1]            else:

    else:                st.success("âœ… é€™å¯èƒ½æ˜¯æ­£å¸¸éƒµä»¶ (Ham)")

        y_prob = None        

            with col2:

    return {            st.subheader("é æ¸¬æ©Ÿç‡")

        'model': model,            st.write(f"åƒåœ¾éƒµä»¶æ©Ÿç‡: {probability[0][1]:.2%}")

        'model_name': model_name,            st.write(f"æ­£å¸¸éƒµä»¶æ©Ÿç‡: {probability[0][0]:.2%}")

        'accuracy': accuracy_score(y_test, y_pred),            

        'precision': precision_score(y_test, y_pred),            # Display probability bar

        'recall': recall_score(y_test, y_pred),            st.progress(float(probability[0][1]))

        'f1': f1_score(y_test, y_pred),

        'train_time': train_time,with tab2:

        'y_pred': y_pred,    st.header("æ•¸æ“šåˆ†æ")

        'y_prob': y_prob    

    }    # Display basic statistics

    st.subheader("æ•¸æ“šçµ±è¨ˆ")

def create_confusion_matrix(y_test, y_pred, model_name):    st.write("åƒåœ¾éƒµä»¶æ¯”ä¾‹:", f"{(df['col_0'] == 'spam').mean():.2%}")

    cm = confusion_matrix(y_test, y_pred)    st.write("ç¸½æ•¸æ“šé‡:", len(df))

    fig = go.Figure(data=go.Heatmap(    

        z=cm,    # Model performance metrics

        x=['Ham', 'Spam'],    st.subheader("æ¨¡å‹æ€§èƒ½")

        y=['Ham', 'Spam'],    

        colorscale='Blues',    # Prepare data for metrics

        text=cm,    X = TfidfVectorizer(max_features=1000).fit_transform(df['text_clean'])

        texttemplate='%{text}',    y = (df['col_0'] == 'spam').astype(int)

        showscale=True    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    ))    

    fig.update_layout(    model = RandomForestClassifier(n_estimators=100, random_state=42)

        title=f'{model_name} - æ··æ·†çŸ©é™£',    model.fit(X_train, y_train)

        xaxis_title='é æ¸¬é¡åˆ¥',    

        yaxis_title='å¯¦éš›é¡åˆ¥',    y_pred = model.predict(X_test)

        height=400    

    )    # Display metrics

    return fig    col1, col2 = st.columns(2)

    

def create_roc_curve(y_test, y_prob, model_name):    with col1:

    if y_prob is None:        st.metric("æ¨¡å‹æº–ç¢ºç‡", f"{accuracy_score(y_test, y_pred):.2%}")

        return None    

    fpr, tpr, _ = roc_curve(y_test, y_prob)    with col2:

    roc_auc = auc(fpr, tpr)        st.metric("é æ¸¬æ­£ç¢ºç‡", f"{accuracy_score(y_test, y_pred):.2%}")

    

    fig = go.Figure()# Footer

    fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines',st.markdown("---")

                             name=f'{model_name} (AUC = {roc_auc:.3f})'))st.markdown("ä½œè€…ï¼š[Your Name] | [GitHub]()")

    fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines',
                             name='éš¨æ©Ÿ', line=dict(dash='dash')))
    fig.update_layout(title=f'{model_name} - ROC æ›²ç·š',
                      xaxis_title='False Positive Rate',
                      yaxis_title='True Positive Rate',
                      height=400)
    return fig

# Load data
df = load_data()
if df is None:
    st.stop()

# Prepare data
vectorizer = TfidfVectorizer(max_features=max_features)
X = vectorizer.fit_transform(df['text_clean'])
y = (df['col_0'] == 'spam').astype(int)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)

# Tabs
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š æ•¸æ“šæ¦‚è¦½", "ğŸ¤– æ¨¡å‹è¨“ç·´", "ğŸ”® å³æ™‚é æ¸¬", "ğŸ“ˆ æ€§èƒ½åˆ†æ"])

with tab1:
    st.header("æ•¸æ“šé›†æ¦‚è¦½")
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ç¸½æ¨£æœ¬æ•¸", len(df))
    with col2:
        st.metric("åƒåœ¾éƒµä»¶", (df['col_0'] == 'spam').sum())
    with col3:
        st.metric("æ­£å¸¸éƒµä»¶", (df['col_0'] == 'ham').sum())
    with col4:
        st.metric("åƒåœ¾æ¯”ä¾‹", f"{(df['col_0'] == 'spam').mean():.1%}")
    
    col1, col2 = st.columns(2)
    with col1:
        class_dist = df['col_0'].value_counts()
        fig = px.pie(values=class_dist.values, names=class_dist.index, title="é¡åˆ¥åˆ†å¸ƒ")
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        df_temp = df.copy()
        df_temp['length'] = df_temp['text_clean'].str.len()
        fig = px.histogram(df_temp, x='length', color='col_0', title="éƒµä»¶é•·åº¦åˆ†å¸ƒ")
        st.plotly_chart(fig, use_container_width=True)

with tab2:
    st.header("æ¨¡å‹è¨“ç·´èˆ‡è©•ä¼°")
    
    if model_choice == "æ‰€æœ‰æ¨¡å‹æ¯”è¼ƒ":
        model_names = ["Random Forest", "Logistic Regression", "NaÃ¯ve Bayes", "SVM (Linear)"]
        all_results = []
        
        for model_name in model_names:
            result = train_model(model_name, X_train, y_train, X_test, y_test)
            all_results.append(result)
        
        metrics_df = pd.DataFrame([{
            'æ¨¡å‹': r['model_name'],
            'æº–ç¢ºç‡': f"{r['accuracy']:.4f}",
            'ç²¾ç¢ºç‡': f"{r['precision']:.4f}",
            'å¬å›ç‡': f"{r['recall']:.4f}",
            'F1åˆ†æ•¸': f"{r['f1']:.4f}",
            'è¨“ç·´æ™‚é–“': f"{r['train_time']:.3f}s"
        } for r in all_results])
        st.dataframe(metrics_df, use_container_width=True)
        
        # Comparison chart
        fig = make_subplots(rows=2, cols=2,
                           subplot_titles=('æº–ç¢ºç‡', 'ç²¾ç¢ºç‡', 'å¬å›ç‡', 'F1åˆ†æ•¸'))
        models = [r['model_name'] for r in all_results]
        positions = [(1,1), (1,2), (2,1), (2,2)]
        metrics = ['accuracy', 'precision', 'recall', 'f1']
        
        for idx, metric in enumerate(metrics):
            row, col = positions[idx]
            values = [r[metric] for r in all_results]
            fig.add_trace(go.Bar(x=models, y=values), row=row, col=col)
            fig.update_yaxes(range=[0, 1], row=row, col=col)
        
        fig.update_layout(height=600, showlegend=False)
        st.plotly_chart(fig, use_container_width=True)
        
    else:
        result = train_model(model_choice, X_train, y_train, X_test, y_test)
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æº–ç¢ºç‡", f"{result['accuracy']:.4f}")
        with col2:
            st.metric("ç²¾ç¢ºç‡", f"{result['precision']:.4f}")
        with col3:
            st.metric("å¬å›ç‡", f"{result['recall']:.4f}")
        with col4:
            st.metric("F1åˆ†æ•¸", f"{result['f1']:.4f}")
        
        col1, col2 = st.columns(2)
        with col1:
            fig_cm = create_confusion_matrix(y_test, result['y_pred'], model_choice)
            st.plotly_chart(fig_cm, use_container_width=True)
        
        with col2:
            if result['y_prob'] is not None:
                fig_roc = create_roc_curve(y_test, result['y_prob'], model_choice)
                st.plotly_chart(fig_roc, use_container_width=True)

with tab3:
    st.header("å³æ™‚é æ¸¬")
    
    pred_model = st.selectbox("é¸æ“‡æ¨¡å‹", ["Random Forest", "Logistic Regression", "NaÃ¯ve Bayes", "SVM (Linear)"])
    user_input = st.text_area("è¼¸å…¥éƒµä»¶å…§å®¹ï¼š", height=150)
    
    if user_input:
        result = train_model(pred_model, X_train, y_train, X_test, y_test)
        model = result['model']
        
        user_vector = vectorizer.transform([user_input])
        prediction = model.predict(user_vector)[0]
        
        if hasattr(model, 'predict_proba'):
            prob = model.predict_proba(user_vector)[0]
            spam_prob = prob[1]
        else:
            spam_prob = None
        
        if prediction == 1:
            st.error("âš ï¸ åƒåœ¾éƒµä»¶ (Spam)")
        else:
            st.success("âœ… æ­£å¸¸éƒµä»¶ (Ham)")
        
        if spam_prob is not None:
            st.progress(float(spam_prob), text=f"åƒåœ¾éƒµä»¶æ©Ÿç‡: {spam_prob:.2%}")

with tab4:
    st.header("æ€§èƒ½åˆ†æ")
    st.markdown("""
    ### æ¨¡å‹èªªæ˜
    
    1. **Random Forest**: é›†æˆå­¸ç¿’ï¼Œé«˜æº–ç¢ºç‡
    2. **Logistic Regression**: ç°¡å–®å¿«é€Ÿï¼Œå¯è§£é‡‹æ€§å¼·
    3. **NaÃ¯ve Bayes**: é©åˆæ–‡æœ¬åˆ†é¡
    4. **SVM Linear**: é«˜ç¶­ç©ºé–“æ•ˆæœå¥½
    
    ### CRISP-DM æ–¹æ³•è«–
    
    æœ¬å°ˆæ¡ˆéµå¾ªæ¨™æº–çš„ CRISP-DM æµç¨‹ï¼š
    - Phase 1: å•†æ¥­ç†è§£
    - Phase 2: è³‡æ–™ç†è§£
    - Phase 3: è³‡æ–™æº–å‚™
    - Phase 4: å»ºæ¨¡
    - Phase 5: è©•ä¼°
    - Phase 6: éƒ¨ç½²
    """)

st.markdown("---")
st.markdown("ä½œè€…ï¼šKatherine623 | å­¸è™Ÿï¼š5114056002 | [GitHub](https://github.com/Katherine623/hw3)")
