import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import nltk
from nltk.corpus import stopwords
import plotly.express as px
import plotly.graph_objects as go

# Download required NLTK data
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')
try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')

# Set page configuration
st.set_page_config(
    page_title="Spam/Ham Classifier",
    page_icon="ğŸ“§",
    layout="wide"
)

# Add title and description
st.title("åƒåœ¾éƒµä»¶åˆ†é¡ç³»çµ± - Spam/Ham Classifier")
st.markdown("""
é€™æ˜¯ä¸€å€‹ä½¿ç”¨æ©Ÿå™¨å­¸ç¿’æŠ€è¡“çš„åƒåœ¾éƒµä»¶åˆ†é¡ç³»çµ±ã€‚ç³»çµ±èƒ½å¤ åˆ†æéƒµä»¶å…§å®¹ï¼Œä¸¦é æ¸¬å®ƒæ˜¯åƒåœ¾éƒµä»¶ï¼ˆspamï¼‰é‚„æ˜¯æ­£å¸¸éƒµä»¶ï¼ˆhamï¼‰ã€‚
""")

# Load and preprocess data
@st.cache_data
def load_data():
    df = pd.read_csv('sms_spam_clean.csv')
    return df

# Load the data
df = load_data()

# Create tabs
tab1, tab2 = st.tabs(["é æ¸¬", "æ•¸æ“šåˆ†æ"])

with tab1:
    st.header("éƒµä»¶åˆ†é¡é æ¸¬")
    
    # Text input for prediction
    user_input = st.text_area("è«‹è¼¸å…¥è¦åˆ†é¡çš„éƒµä»¶å…§å®¹ï¼š", height=100)
    
    # Model training and prediction
    if user_input:
        # Prepare the model
        vectorizer = TfidfVectorizer(max_features=1000)
        X = vectorizer.fit_transform(df['text_clean'])
        y = (df['col_0'] == 'spam').astype(int)
        
        # Split the data
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # Train the model
        model = RandomForestClassifier(n_estimators=100, random_state=42)
        model.fit(X_train, y_train)
        
        # Make prediction
        user_vector = vectorizer.transform([user_input])
        prediction = model.predict(user_vector)
        probability = model.predict_proba(user_vector)
        
        # Show results
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("é æ¸¬çµæœ")
            if prediction[0] == 1:
                st.error("âš ï¸ é€™å¯èƒ½æ˜¯åƒåœ¾éƒµä»¶ (Spam)")
            else:
                st.success("âœ… é€™å¯èƒ½æ˜¯æ­£å¸¸éƒµä»¶ (Ham)")
        
        with col2:
            st.subheader("é æ¸¬æ©Ÿç‡")
            st.write(f"åƒåœ¾éƒµä»¶æ©Ÿç‡: {probability[0][1]:.2%}")
            st.write(f"æ­£å¸¸éƒµä»¶æ©Ÿç‡: {probability[0][0]:.2%}")
            
            # Create a gauge chart for spam probability
            fig = go.Figure(go.Indicator(
                mode = "gauge+number",
                value = probability[0][1] * 100,
                title = {'text': "åƒåœ¾éƒµä»¶æ©Ÿç‡"},
                domain = {'x': [0, 1], 'y': [0, 1]},
                gauge = {
                    'axis': {'range': [None, 100]},
                    'steps': [
                        {'range': [0, 50], 'color': "lightgreen"},
                        {'range': [50, 100], 'color': "lightcoral"}
                    ],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': 50
                    }
                }
            ))
            st.plotly_chart(fig)

with tab2:
    st.header("æ•¸æ“šåˆ†æ")
    
    # Display class distribution
    st.subheader("é¡åˆ¥åˆ†å¸ƒ")
    class_dist = df['col_0'].value_counts()
    fig = px.pie(values=class_dist.values, names=class_dist.index, 
                 title="Ham vs Spam Distribution")
    st.plotly_chart(fig)
    
    # Display message length distribution
    st.subheader("éƒµä»¶é•·åº¦åˆ†å¸ƒ")
    df['message_length'] = df['text_clean'].str.len()
    fig = px.histogram(df, x='message_length', color='col_0', 
                      title="Message Length Distribution by Class",
                      labels={'message_length': 'Message Length', 'col_0': 'Class'})
    st.plotly_chart(fig)
    
    # Model performance metrics
    st.subheader("æ¨¡å‹æ€§èƒ½")
    
    # Prepare data for metrics
    X = TfidfVectorizer(max_features=1000).fit_transform(df['text_clean'])
    y = (df['col_0'] == 'spam').astype(int)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    
    y_pred = model.predict(X_test)
    
    # Display metrics
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("æ¨¡å‹æº–ç¢ºç‡", f"{accuracy_score(y_test, y_pred):.2%}")
    
    with col2:
        report = classification_report(y_test, y_pred, output_dict=True)
        st.metric("F1 åˆ†æ•¸ (Spam)", f"{report['1']['f1-score']:.2%}")

# Footer
st.markdown("---")
st.markdown("ä½œè€…ï¼š[Your Name] | [GitHub]()")
