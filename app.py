import streamlit as stimport streamlit as stimport streamlit as st

import pandas as pd

import numpy as npimport pandas as pdimport pandas as pd

from sklearn.model_selection import train_test_split

from sklearn.feature_extraction.text import TfidfVectorizerimport numpy as npfrom sklearn.model_selection import train_test_split

from sklearn.ensemble import RandomForestClassifier

from sklearn.linear_model import LogisticRegressionfrom sklearn.model_selection import train_test_splitfrom sklearn.feature_extraction.text import TfidfVectorizer

from sklearn.naive_bayes import MultinomialNB

from sklearn.svm import LinearSVCfrom sklearn.feature_extraction.text import TfidfVectorizerfrom sklearn.ensemble import RandomForestClassifier

from sklearn.metrics import (

    accuracy_score, precision_score, recall_score, f1_score,from sklearn.ensemble import RandomForestClassifierfrom sklearn.metrics import accuracy_score

    confusion_matrix, roc_curve, auc

)from sklearn.linear_model import LogisticRegression

import plotly.express as px

import plotly.graph_objects as gofrom sklearn.naive_bayes import MultinomialNB# Set page configuration

from plotly.subplots import make_subplots

import timefrom sklearn.svm import LinearSVCst.set_page_config(



# Set page configurationfrom sklearn.metrics import (    page_title="Spam/Ham Classifier",

st.set_page_config(

    page_title="åƒåœ¾éƒµä»¶åˆ†é¡ç³»çµ±",    accuracy_score, precision_score, recall_score, f1_score,    page_icon="ğŸ“§",

    page_icon="ğŸ“§",

    layout="wide"    confusion_matrix, roc_curve, auc    layout="wide"

)

))

# Title

st.title("ğŸ“§ åƒåœ¾éƒµä»¶åˆ†é¡ç³»çµ±")import plotly.express as px

st.markdown("ä½¿ç”¨å¤šç¨®æ©Ÿå™¨å­¸ç¿’æ¨¡å‹é€²è¡Œåƒåœ¾éƒµä»¶åˆ†é¡")

import plotly.graph_objects as go# Add title and description

# Sidebar

with st.sidebar:from plotly.subplots import make_subplotsst.title("åƒåœ¾éƒµä»¶åˆ†é¡ç³»çµ± - Spam/Ham Classifier")

    st.title("è¨­å®šé¸é …")

    import timest.markdown("""

    model_choice = st.selectbox(

        "é¸æ“‡åˆ†é¡å™¨",é€™æ˜¯ä¸€å€‹ä½¿ç”¨æ©Ÿå™¨å­¸ç¿’æŠ€è¡“çš„åƒåœ¾éƒµä»¶åˆ†é¡ç³»çµ±ã€‚ç³»çµ±èƒ½å¤ åˆ†æéƒµä»¶å…§å®¹ï¼Œä¸¦é æ¸¬å®ƒæ˜¯åƒåœ¾éƒµä»¶ï¼ˆspamï¼‰é‚„æ˜¯æ­£å¸¸éƒµä»¶ï¼ˆhamï¼‰ã€‚

        ["Random Forest", "Logistic Regression", "NaÃ¯ve Bayes", "SVM (Linear)", "æ‰€æœ‰æ¨¡å‹æ¯”è¼ƒ"]

    )# Set page configuration""")

    

    test_size = st.slider("æ¸¬è©¦é›†æ¯”ä¾‹", 0.1, 0.4, 0.2, 0.05)st.set_page_config(

    max_features = st.slider("æœ€å¤§ç‰¹å¾µæ•¸ (TF-IDF)", 500, 2000, 1000, 100)

    page_title="åƒåœ¾éƒµä»¶åˆ†é¡ç³»çµ±",# Load and preprocess data

# Load data

@st.cache_data    page_icon="ğŸ“§",@st.cache_data

def load_data():

    try:    layout="wide"def load_data():

        df = pd.read_csv('sms_spam_clean.csv')

        return df)    try:

    except Exception as e:

        st.error(f"è®€å–è³‡æ–™éŒ¯èª¤: {str(e)}")        df = pd.read_csv('sms_spam_clean.csv')

        return None

# Title        return df

# Train model

@st.cache_datast.title("ğŸ“§ åƒåœ¾éƒµä»¶åˆ†é¡ç³»çµ±")    except Exception as e:

def train_model(model_name, X_train, y_train, X_test, y_test):

    if model_name == "Random Forest":st.markdown("ä½¿ç”¨å¤šç¨®æ©Ÿå™¨å­¸ç¿’æ¨¡å‹é€²è¡Œåƒåœ¾éƒµä»¶åˆ†é¡")        st.error(f"è®€å–è³‡æ–™éŒ¯èª¤: {str(e)}")

        model = RandomForestClassifier(n_estimators=100, random_state=42)

    elif model_name == "Logistic Regression":        return None

        model = LogisticRegression(max_iter=1000, random_state=42)

    elif model_name == "NaÃ¯ve Bayes":# Sidebar

        model = MultinomialNB()

    else:  # SVMwith st.sidebar:# Load the data

        model = LinearSVC(random_state=42, max_iter=2000)

        st.title("è¨­å®šé¸é …")df = load_data()

    start_time = time.time()

    model.fit(X_train, y_train)    

    train_time = time.time() - start_time

        model_choice = st.selectbox(if df is None:

    y_pred = model.predict(X_test)

            "é¸æ“‡åˆ†é¡å™¨",    st.stop()

    # Get probabilities if available

    if hasattr(model, 'predict_proba'):        ["Random Forest", "Logistic Regression", "NaÃ¯ve Bayes", "SVM (Linear)", "æ‰€æœ‰æ¨¡å‹æ¯”è¼ƒ"]

        y_prob = model.predict_proba(X_test)[:, 1]

    else:    )# Create tabs

        y_prob = None

        tab1, tab2 = st.tabs(["é æ¸¬", "æ•¸æ“šåˆ†æ"])

    return {

        'model': model,    test_size = st.slider("æ¸¬è©¦é›†æ¯”ä¾‹", 0.1, 0.4, 0.2, 0.05)

        'model_name': model_name,

        'accuracy': accuracy_score(y_test, y_pred),    max_features = st.slider("æœ€å¤§ç‰¹å¾µæ•¸ (TF-IDF)", 500, 2000, 1000, 100)with tab1:

        'precision': precision_score(y_test, y_pred),

        'recall': recall_score(y_test, y_pred),    st.header("éƒµä»¶åˆ†é¡é æ¸¬")

        'f1': f1_score(y_test, y_pred),

        'train_time': train_time,# Load data    

        'y_pred': y_pred,

        'y_prob': y_prob@st.cache_data    # Text input for prediction

    }

def load_data():    user_input = st.text_area("è«‹è¼¸å…¥è¦åˆ†é¡çš„éƒµä»¶å…§å®¹ï¼š", height=100)

def create_confusion_matrix(y_test, y_pred, model_name):

    cm = confusion_matrix(y_test, y_pred)    try:    

    fig = go.Figure(data=go.Heatmap(

        z=cm,        df = pd.read_csv('sms_spam_clean.csv')    # Model training and prediction

        x=['Ham', 'Spam'],

        y=['Ham', 'Spam'],        return df    if user_input:

        colorscale='Blues',

        text=cm,    except Exception as e:        # Prepare the model

        texttemplate='%{text}',

        showscale=True        st.error(f"è®€å–è³‡æ–™éŒ¯èª¤: {str(e)}")        vectorizer = TfidfVectorizer(max_features=1000)

    ))

    fig.update_layout(        return None        X = vectorizer.fit_transform(df['text_clean'])

        title=f'{model_name} - æ··æ·†çŸ©é™£',

        xaxis_title='é æ¸¬é¡åˆ¥',        y = (df['col_0'] == 'spam').astype(int)

        yaxis_title='å¯¦éš›é¡åˆ¥',

        height=400# Train model        

    )

    return fig@st.cache_data        # Split the data



def create_roc_curve(y_test, y_prob, model_name):def train_model(model_name, X_train, y_train, X_test, y_test):        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    if y_prob is None:

        return None    if model_name == "Random Forest":        

    fpr, tpr, _ = roc_curve(y_test, y_prob)

    roc_auc = auc(fpr, tpr)        model = RandomForestClassifier(n_estimators=100, random_state=42)        # Train the model

    

    fig = go.Figure()    elif model_name == "Logistic Regression":        model = RandomForestClassifier(n_estimators=100, random_state=42)

    fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines',

                             name=f'{model_name} (AUC = {roc_auc:.3f})'))        model = LogisticRegression(max_iter=1000, random_state=42)        model.fit(X_train, y_train)

    fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines',

                             name='éš¨æ©Ÿ', line=dict(dash='dash')))    elif model_name == "NaÃ¯ve Bayes":        

    fig.update_layout(title=f'{model_name} - ROC æ›²ç·š',

                      xaxis_title='False Positive Rate',        model = MultinomialNB()        # Make prediction

                      yaxis_title='True Positive Rate',

                      height=400)    else:  # SVM        user_vector = vectorizer.transform([user_input])

    return fig

        model = LinearSVC(random_state=42, max_iter=2000)        prediction = model.predict(user_vector)

# Load data

df = load_data()            probability = model.predict_proba(user_vector)

if df is None:

    st.stop()    start_time = time.time()        



# Prepare data    model.fit(X_train, y_train)        # Show results

vectorizer = TfidfVectorizer(max_features=max_features)

X = vectorizer.fit_transform(df['text_clean'])    train_time = time.time() - start_time        col1, col2 = st.columns(2)

y = (df['col_0'] == 'spam').astype(int)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)            



# Tabs    y_pred = model.predict(X_test)        with col1:

tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š æ•¸æ“šæ¦‚è¦½", "ğŸ¤– æ¨¡å‹è¨“ç·´", "ğŸ”® å³æ™‚é æ¸¬", "ğŸ“ˆ æ€§èƒ½åˆ†æ"])

                st.subheader("é æ¸¬çµæœ")

with tab1:

    st.header("æ•¸æ“šé›†æ¦‚è¦½")    # Get probabilities if available            if prediction[0] == 1:

    col1, col2, col3, col4 = st.columns(4)

    with col1:    if hasattr(model, 'predict_proba'):                st.error("âš ï¸ é€™å¯èƒ½æ˜¯åƒåœ¾éƒµä»¶ (Spam)")

        st.metric("ç¸½æ¨£æœ¬æ•¸", len(df))

    with col2:        y_prob = model.predict_proba(X_test)[:, 1]            else:

        st.metric("åƒåœ¾éƒµä»¶", (df['col_0'] == 'spam').sum())

    with col3:    else:                st.success("âœ… é€™å¯èƒ½æ˜¯æ­£å¸¸éƒµä»¶ (Ham)")

        st.metric("æ­£å¸¸éƒµä»¶", (df['col_0'] == 'ham').sum())

    with col4:        y_prob = None        

        st.metric("åƒåœ¾æ¯”ä¾‹", f"{(df['col_0'] == 'spam').mean():.1%}")

                with col2:

    col1, col2 = st.columns(2)

    with col1:    return {            st.subheader("é æ¸¬æ©Ÿç‡")

        class_dist = df['col_0'].value_counts()

        fig = px.pie(values=class_dist.values, names=class_dist.index, title="é¡åˆ¥åˆ†å¸ƒ")        'model': model,            st.write(f"åƒåœ¾éƒµä»¶æ©Ÿç‡: {probability[0][1]:.2%}")

        st.plotly_chart(fig, use_container_width=True)

            'model_name': model_name,            st.write(f"æ­£å¸¸éƒµä»¶æ©Ÿç‡: {probability[0][0]:.2%}")

    with col2:

        df_temp = df.copy()        'accuracy': accuracy_score(y_test, y_pred),            

        df_temp['length'] = df_temp['text_clean'].str.len()

        fig = px.histogram(df_temp, x='length', color='col_0', title="éƒµä»¶é•·åº¦åˆ†å¸ƒ")        'precision': precision_score(y_test, y_pred),            # Display probability bar

        st.plotly_chart(fig, use_container_width=True)

        'recall': recall_score(y_test, y_pred),            st.progress(float(probability[0][1]))

with tab2:

    st.header("æ¨¡å‹è¨“ç·´èˆ‡è©•ä¼°")        'f1': f1_score(y_test, y_pred),

    

    if model_choice == "æ‰€æœ‰æ¨¡å‹æ¯”è¼ƒ":        'train_time': train_time,with tab2:

        model_names = ["Random Forest", "Logistic Regression", "NaÃ¯ve Bayes", "SVM (Linear)"]

        all_results = []        'y_pred': y_pred,    st.header("æ•¸æ“šåˆ†æ")

        

        for model_name in model_names:        'y_prob': y_prob    

            result = train_model(model_name, X_train, y_train, X_test, y_test)

            all_results.append(result)    }    # Display basic statistics

        

        metrics_df = pd.DataFrame([{    st.subheader("æ•¸æ“šçµ±è¨ˆ")

            'æ¨¡å‹': r['model_name'],

            'æº–ç¢ºç‡': f"{r['accuracy']:.4f}",def create_confusion_matrix(y_test, y_pred, model_name):    st.write("åƒåœ¾éƒµä»¶æ¯”ä¾‹:", f"{(df['col_0'] == 'spam').mean():.2%}")

            'ç²¾ç¢ºç‡': f"{r['precision']:.4f}",

            'å¬å›ç‡': f"{r['recall']:.4f}",    cm = confusion_matrix(y_test, y_pred)    st.write("ç¸½æ•¸æ“šé‡:", len(df))

            'F1åˆ†æ•¸': f"{r['f1']:.4f}",

            'è¨“ç·´æ™‚é–“': f"{r['train_time']:.3f}s"    fig = go.Figure(data=go.Heatmap(    

        } for r in all_results])

        st.dataframe(metrics_df, use_container_width=True)        z=cm,    # Model performance metrics

        

        # Comparison chart        x=['Ham', 'Spam'],    st.subheader("æ¨¡å‹æ€§èƒ½")

        fig = make_subplots(rows=2, cols=2,

                           subplot_titles=('æº–ç¢ºç‡', 'ç²¾ç¢ºç‡', 'å¬å›ç‡', 'F1åˆ†æ•¸'))        y=['Ham', 'Spam'],    

        models = [r['model_name'] for r in all_results]

        positions = [(1,1), (1,2), (2,1), (2,2)]        colorscale='Blues',    # Prepare data for metrics

        metrics = ['accuracy', 'precision', 'recall', 'f1']

                text=cm,    X = TfidfVectorizer(max_features=1000).fit_transform(df['text_clean'])

        for idx, metric in enumerate(metrics):

            row, col = positions[idx]        texttemplate='%{text}',    y = (df['col_0'] == 'spam').astype(int)

            values = [r[metric] for r in all_results]

            fig.add_trace(go.Bar(x=models, y=values), row=row, col=col)        showscale=True    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

            fig.update_yaxes(range=[0, 1], row=row, col=col)

            ))    

        fig.update_layout(height=600, showlegend=False)

        st.plotly_chart(fig, use_container_width=True)    fig.update_layout(    model = RandomForestClassifier(n_estimators=100, random_state=42)

        

    else:        title=f'{model_name} - æ··æ·†çŸ©é™£',    model.fit(X_train, y_train)

        result = train_model(model_choice, X_train, y_train, X_test, y_test)

                xaxis_title='é æ¸¬é¡åˆ¥',    

        col1, col2, col3, col4 = st.columns(4)

        with col1:        yaxis_title='å¯¦éš›é¡åˆ¥',    y_pred = model.predict(X_test)

            st.metric("æº–ç¢ºç‡", f"{result['accuracy']:.4f}")

        with col2:        height=400    

            st.metric("ç²¾ç¢ºç‡", f"{result['precision']:.4f}")

        with col3:    )    # Display metrics

            st.metric("å¬å›ç‡", f"{result['recall']:.4f}")

        with col4:    return fig    col1, col2 = st.columns(2)

            st.metric("F1åˆ†æ•¸", f"{result['f1']:.4f}")

            

        col1, col2 = st.columns(2)

        with col1:def create_roc_curve(y_test, y_prob, model_name):    with col1:

            fig_cm = create_confusion_matrix(y_test, result['y_pred'], model_choice)

            st.plotly_chart(fig_cm, use_container_width=True)    if y_prob is None:        st.metric("æ¨¡å‹æº–ç¢ºç‡", f"{accuracy_score(y_test, y_pred):.2%}")

        

        with col2:        return None    

            if result['y_prob'] is not None:

                fig_roc = create_roc_curve(y_test, result['y_prob'], model_choice)    fpr, tpr, _ = roc_curve(y_test, y_prob)    with col2:

                st.plotly_chart(fig_roc, use_container_width=True)

    roc_auc = auc(fpr, tpr)        st.metric("é æ¸¬æ­£ç¢ºç‡", f"{accuracy_score(y_test, y_pred):.2%}")

with tab3:

    st.header("å³æ™‚é æ¸¬")    

    

    pred_model = st.selectbox("é¸æ“‡æ¨¡å‹", ["Random Forest", "Logistic Regression", "NaÃ¯ve Bayes", "SVM (Linear)"])    fig = go.Figure()# Footer

    user_input = st.text_area("è¼¸å…¥éƒµä»¶å…§å®¹ï¼š", height=150)

        fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines',st.markdown("---")

    if user_input:

        result = train_model(pred_model, X_train, y_train, X_test, y_test)                             name=f'{model_name} (AUC = {roc_auc:.3f})'))st.markdown("ä½œè€…ï¼š[Your Name] | [GitHub]()")

        model = result['model']

            fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines',

        user_vector = vectorizer.transform([user_input])                             name='éš¨æ©Ÿ', line=dict(dash='dash')))

        prediction = model.predict(user_vector)[0]    fig.update_layout(title=f'{model_name} - ROC æ›²ç·š',

                              xaxis_title='False Positive Rate',

        if hasattr(model, 'predict_proba'):                      yaxis_title='True Positive Rate',

            prob = model.predict_proba(user_vector)[0]                      height=400)

            spam_prob = prob[1]    return fig

        else:

            spam_prob = None# Load data

        df = load_data()

        if prediction == 1:if df is None:

            st.error("âš ï¸ åƒåœ¾éƒµä»¶ (Spam)")    st.stop()

        else:

            st.success("âœ… æ­£å¸¸éƒµä»¶ (Ham)")# Prepare data

        vectorizer = TfidfVectorizer(max_features=max_features)

        if spam_prob is not None:X = vectorizer.fit_transform(df['text_clean'])

            st.progress(float(spam_prob), text=f"åƒåœ¾éƒµä»¶æ©Ÿç‡: {spam_prob:.2%}")y = (df['col_0'] == 'spam').astype(int)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)

with tab4:

    st.header("æ€§èƒ½åˆ†æ")# Tabs

    st.markdown("""tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š æ•¸æ“šæ¦‚è¦½", "ğŸ¤– æ¨¡å‹è¨“ç·´", "ğŸ”® å³æ™‚é æ¸¬", "ğŸ“ˆ æ€§èƒ½åˆ†æ"])

    ### æ¨¡å‹èªªæ˜

    with tab1:

    1. **Random Forest**: é›†æˆå­¸ç¿’ï¼Œé«˜æº–ç¢ºç‡    st.header("æ•¸æ“šé›†æ¦‚è¦½")

    2. **Logistic Regression**: ç°¡å–®å¿«é€Ÿï¼Œå¯è§£é‡‹æ€§å¼·    col1, col2, col3, col4 = st.columns(4)

    3. **NaÃ¯ve Bayes**: é©åˆæ–‡æœ¬åˆ†é¡    with col1:

    4. **SVM Linear**: é«˜ç¶­ç©ºé–“æ•ˆæœå¥½        st.metric("ç¸½æ¨£æœ¬æ•¸", len(df))

        with col2:

    ### CRISP-DM æ–¹æ³•è«–        st.metric("åƒåœ¾éƒµä»¶", (df['col_0'] == 'spam').sum())

        with col3:

    æœ¬å°ˆæ¡ˆéµå¾ªæ¨™æº–çš„ CRISP-DM æµç¨‹ï¼š        st.metric("æ­£å¸¸éƒµä»¶", (df['col_0'] == 'ham').sum())

    - Phase 1: å•†æ¥­ç†è§£    with col4:

    - Phase 2: è³‡æ–™ç†è§£        st.metric("åƒåœ¾æ¯”ä¾‹", f"{(df['col_0'] == 'spam').mean():.1%}")

    - Phase 3: è³‡æ–™æº–å‚™    

    - Phase 4: å»ºæ¨¡    col1, col2 = st.columns(2)

    - Phase 5: è©•ä¼°    with col1:

    - Phase 6: éƒ¨ç½²        class_dist = df['col_0'].value_counts()

    """)        fig = px.pie(values=class_dist.values, names=class_dist.index, title="é¡åˆ¥åˆ†å¸ƒ")

        st.plotly_chart(fig, use_container_width=True)

st.markdown("---")    

st.markdown("ä½œè€…ï¼šKatherine623 | å­¸è™Ÿï¼š5114056002 | [GitHub](https://github.com/Katherine623/hw3)")    with col2:

        df_temp = df.copy()
        df_temp['length'] = df_temp['text_clean'].str.len()
        fig = px.histogram(df_temp, x='length', color='col_0', title="éƒµä»¶é•·åº¦åˆ†å¸ƒ")
        st.plotly_chart(fig, use_container_width=True)

with tab2:
    st.header("æ¨¡å‹è¨“ç·´èˆ‡è©•ä¼°")
    
    if model_choice == "æ‰€æœ‰æ¨¡å‹æ¯”è¼ƒ":
        model_names = ["Random Forest", "Logistic Regression", "NaÃ¯ve Bayes", "SVM (Linear)"]
        all_results = []
        
        for model_name in model_names:
            result = train_model(model_name, X_train, y_train, X_test, y_test)
            all_results.append(result)
        
        metrics_df = pd.DataFrame([{
            'æ¨¡å‹': r['model_name'],
            'æº–ç¢ºç‡': f"{r['accuracy']:.4f}",
            'ç²¾ç¢ºç‡': f"{r['precision']:.4f}",
            'å¬å›ç‡': f"{r['recall']:.4f}",
            'F1åˆ†æ•¸': f"{r['f1']:.4f}",
            'è¨“ç·´æ™‚é–“': f"{r['train_time']:.3f}s"
        } for r in all_results])
        st.dataframe(metrics_df, use_container_width=True)
        
        # Comparison chart
        fig = make_subplots(rows=2, cols=2,
                           subplot_titles=('æº–ç¢ºç‡', 'ç²¾ç¢ºç‡', 'å¬å›ç‡', 'F1åˆ†æ•¸'))
        models = [r['model_name'] for r in all_results]
        positions = [(1,1), (1,2), (2,1), (2,2)]
        metrics = ['accuracy', 'precision', 'recall', 'f1']
        
        for idx, metric in enumerate(metrics):
            row, col = positions[idx]
            values = [r[metric] for r in all_results]
            fig.add_trace(go.Bar(x=models, y=values), row=row, col=col)
            fig.update_yaxes(range=[0, 1], row=row, col=col)
        
        fig.update_layout(height=600, showlegend=False)
        st.plotly_chart(fig, use_container_width=True)
        
    else:
        result = train_model(model_choice, X_train, y_train, X_test, y_test)
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æº–ç¢ºç‡", f"{result['accuracy']:.4f}")
        with col2:
            st.metric("ç²¾ç¢ºç‡", f"{result['precision']:.4f}")
        with col3:
            st.metric("å¬å›ç‡", f"{result['recall']:.4f}")
        with col4:
            st.metric("F1åˆ†æ•¸", f"{result['f1']:.4f}")
        
        col1, col2 = st.columns(2)
        with col1:
            fig_cm = create_confusion_matrix(y_test, result['y_pred'], model_choice)
            st.plotly_chart(fig_cm, use_container_width=True)
        
        with col2:
            if result['y_prob'] is not None:
                fig_roc = create_roc_curve(y_test, result['y_prob'], model_choice)
                st.plotly_chart(fig_roc, use_container_width=True)

with tab3:
    st.header("å³æ™‚é æ¸¬")
    
    pred_model = st.selectbox("é¸æ“‡æ¨¡å‹", ["Random Forest", "Logistic Regression", "NaÃ¯ve Bayes", "SVM (Linear)"])
    user_input = st.text_area("è¼¸å…¥éƒµä»¶å…§å®¹ï¼š", height=150)
    
    if user_input:
        result = train_model(pred_model, X_train, y_train, X_test, y_test)
        model = result['model']
        
        user_vector = vectorizer.transform([user_input])
        prediction = model.predict(user_vector)[0]
        
        if hasattr(model, 'predict_proba'):
            prob = model.predict_proba(user_vector)[0]
            spam_prob = prob[1]
        else:
            spam_prob = None
        
        if prediction == 1:
            st.error("âš ï¸ åƒåœ¾éƒµä»¶ (Spam)")
        else:
            st.success("âœ… æ­£å¸¸éƒµä»¶ (Ham)")
        
        if spam_prob is not None:
            st.progress(float(spam_prob), text=f"åƒåœ¾éƒµä»¶æ©Ÿç‡: {spam_prob:.2%}")

with tab4:
    st.header("æ€§èƒ½åˆ†æ")
    st.markdown("""
    ### æ¨¡å‹èªªæ˜
    
    1. **Random Forest**: é›†æˆå­¸ç¿’ï¼Œé«˜æº–ç¢ºç‡
    2. **Logistic Regression**: ç°¡å–®å¿«é€Ÿï¼Œå¯è§£é‡‹æ€§å¼·
    3. **NaÃ¯ve Bayes**: é©åˆæ–‡æœ¬åˆ†é¡
    4. **SVM Linear**: é«˜ç¶­ç©ºé–“æ•ˆæœå¥½
    
    ### CRISP-DM æ–¹æ³•è«–
    
    æœ¬å°ˆæ¡ˆéµå¾ªæ¨™æº–çš„ CRISP-DM æµç¨‹ï¼š
    - Phase 1: å•†æ¥­ç†è§£
    - Phase 2: è³‡æ–™ç†è§£
    - Phase 3: è³‡æ–™æº–å‚™
    - Phase 4: å»ºæ¨¡
    - Phase 5: è©•ä¼°
    - Phase 6: éƒ¨ç½²
    """)

st.markdown("---")
st.markdown("ä½œè€…ï¼šKatherine623 | å­¸è™Ÿï¼š5114056002 | [GitHub](https://github.com/Katherine623/hw3)")
